{
 "metadata": {
  "name": "",
  "signature": "sha256:7956e9d9e196a492048659920b322a2e3da5b46b3ac88369faa0ec6026071e5f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../3st_inserted_mapping/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/li/new/data/cb/3st_inserted_mapping\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###  Consider several possibility of the \"Ns\"(or rather *gaps*)\n",
      "#### 1. the \"Ns\" can be coverd by single read, the Ns can be recovered as mismatches and be replaced, this should be most of the case for the samll gaps.\n",
      "- Something has to be noted, the read has a high (0.1%, compared to the less than 0.01% mismatch and insertion) rate of deletion, so if a samll indel was found to be in a \"deletion region\" of the long read, the deletion should be ignored, and the gap region should be remained.\n",
      "- This can be further confirmed by TRfinder, in this case, this region should be masked by tandem repeat finder, if the region is full of tandem repetor, this singnal should be igored.\n",
      "\n",
      "#### 2. the \"Ns\" cause some **unaligned end**: find the begin and the end, make realignment with some aligner(bwa?muscle?), and give the Ns some repalcements, and fill the \"Ns\". When parsing the unaligned ends, some situations should be treated differently:\n",
      "- No read support --> ignore, unfilled\n",
      "- Unaligned end in both direction\n",
      "  - unalign end overlapped at the end --> filled, caculated the length of the read\n",
      "  - unalign end do not overlap --> double extended, unfilled\n",
      "- Unaligned end in one direction\n",
      "  - align with the beginning of the other edge (for example, 500bp?)\n",
      "    - unalign end overlapped with the beginning of the other edge --> filled\n",
      "    - unalign end do not overlap --> single extended, unfilled\n",
      "\n",
      "#### 3. How long flaking sequence shold the be used?\n",
      "- 200bp? 50bp? 20bp? For the alignment 200bp is long enough, and the pileup of samfiles can indicate the edge of the right mapping\n",
      "\n",
      "#### 4. Keep in mind that the filling of Ns is used for the precise break point detection\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fillname: summary_N.py\n",
      "\n",
      "from Bio import SeqIO\n",
      "import cPickle as pickle\n",
      "\n",
      "def reftodic(fastafile):\n",
      "    \"\"\"\n",
      "    Give a fasta file name, return a dict contains the name and seq\n",
      "    Require Biopython SeqIO medule to parse the sequence into dict, a large genome may take a lot of RAM\n",
      "    \"\"\"\n",
      "    handle = open(fastafile, \"rU\")\n",
      "    record_dict = SeqIO.to_dict(SeqIO.parse(handle, \"fasta\"))\n",
      "    handle.close()\n",
      "    return record_dict\n",
      "\n",
      "def summary_N(record_dict, N_threshold=5):\n",
      "    \"\"\"\n",
      "    Give a function to summary the \"N\"s in the genome, and return a bed like tuple-list to describe the \"N\"s,\n",
      "    Output tuple format: (\"chr\", str,end). chr is type(str), while start and end is type(int)\n",
      "    Note: the hard-masked genome will be regonized as gap\n",
      "    \"\"\"\n",
      "    N_list=[]\n",
      "    for chr in record_dict.keys():\n",
      "        seq=str(record_dict[chr].seq).lower()\n",
      "        left=[]\n",
      "        right=[]\n",
      "        for i,nucl in enumerate(list(seq)):\n",
      "            if nucl==\"n\" and seq[(i-1)]!=\"n\":\n",
      "                left.append(i)\n",
      "            #the right edge can be the end of the chr, then n+1 will raise an error\n",
      "            try:\n",
      "                if nucl==\"n\" and seq[(i+1)]!=\"n\":\n",
      "                    right.append(i)\n",
      "            except Exception:\n",
      "                pass\n",
      "            if i==len(seq) and nucl==\"n\":\n",
      "                right.append(i)\n",
      "        # check if the left edge and right edge are paired. Normally it should be OK.\n",
      "        if len(left)==len(right):\n",
      "            count=0\n",
      "            length_N=0\n",
      "            for i in range(0,len(left)):\n",
      "                N_single=(chr,left[i],right[i])\n",
      "                N_list.append(N_single)\n",
      "                # print some stat out\n",
      "                length_N+=right[i]-left[i]+1\n",
      "                if right[i]-left[i]>=N_threshold:\n",
      "                    count+=1\n",
      "            print \"%s has %d gaps (len> %d bp), total gap length is %d (single N included).\" %(chr,count,N_threshold,length_N)\n",
      "        else:\n",
      "            print \"left\", len(left), \"unequal to\", \"right\", len(right)\n",
      "    #store the N_list as pickle file\n",
      "    with open(\"N_list.dat\",\"wb\") as fp:\n",
      "        pickle.dump(N_list, fp)\n",
      "    return N_list\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    record_dict=reftodic(\"cb4_insertion_filled.fasta\")\n",
      "    aa=summary_N(record_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "V_random has 2 gaps (len> 5 bp), total gap length is 70 (single N included).\n",
        "III_random has 3 gaps (len> 5 bp), total gap length is 6220 (single N included).\n",
        "I has 472 gaps (len> 5 bp), total gap length is 301715 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "I_random has 2 gaps (len> 5 bp), total gap length is 111 (single N included).\n",
        "IV has 503 gaps (len> 5 bp), total gap length is 381080 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "II has 478 gaps (len> 5 bp), total gap length is 428202 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "un has 554 gaps (len> 5 bp), total gap length is 79461 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "V has 484 gaps (len> 5 bp), total gap length is 342172 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "X has 315 gaps (len> 5 bp), total gap length is 331692 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "III has 380 gaps (len> 5 bp), total gap length is 271645 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "IV_random has 1 gaps (len> 5 bp), total gap length is 1462 (single N included).\n",
        "X_random has 0 gaps (len> 5 bp), total gap length is 1 (single N included).\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: check_N.py\n",
      "# restore the database\n",
      "\"\"\"\n",
      "From the pickle file ,restore the N_list\n",
      "and check the Ns within a length range, \n",
      "give the position and the reads that can possibly overlapped the region\n",
      "take the reads from the \n",
      "\"\"\"\n",
      "try: \n",
      "    import cPickle as pickle\n",
      "except Exception:\n",
      "    import pickle as pickle\n",
      "import pysam\n",
      "\n",
      "with open(\"N_list.dat\",\"rb\") as fp:\n",
      "    N_list=pickle.load(fp)\n",
      "    for i in range(1000,2000):\n",
      "        if 10000<N_list[i][2]-N_list[i][1]:\n",
      "            print N_list[i]\n",
      "            chr,start,end=N_list[i]\n",
      "            with pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\") as samfile:\n",
      "                for read in samfile.fetch(chr,start-10,end+10):\n",
      "                    print read.query_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('IV', 3813084, 3827854)\n",
        "mol-32-ab22-022434\n",
        "mol-32-ad1c-064079\n",
        "mol-32-ad1c-025487\n",
        "mol-32-ab22-056006\n",
        "mol-32-ad1c-023255\n",
        "mol-32-ab22-135286\n",
        "mol-32-ad1c-023255\n",
        "('IV', 12592468, 12605466)\n",
        "('IV', 16815074, 16832983)\n",
        "('II', 3691251, 3702042)\n",
        "mol-32-ad1c-023617\n",
        "mol-32-ab22-109541\n",
        "mol-32-ad1c-083720\n",
        "mol-32-ad1c-128917\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the n position, to fill n with the mapped long reads\n",
      "import pysam\n",
      "with pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\") as samfile:\n",
      "    for read in samfile.fetch(\"II\",6029640,6029655): \n",
      "        print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length, read.cigarstring"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ad1c-022195 + 0 12685 12685 II 6019032 6031723 12691 10592M1I17M1D7M6D2068M\n",
        "mol-32-ab22-063362 + 0 11624 11624 II 6019453 6031083 11630 10171M1I17M1D7M6D1428M\n",
        "mol-32-ab22-088824 - 0 10428 10428 II 6019558 6029992 10434 10066M1I17M1D7M6D337M\n",
        "mol-32-ad1c-115785 + 0 10590 10590 II 6019770 6030366 10596 9854M1I17M1D7M6D711M\n",
        "mol-32-ab22-119095 - 0 11961 11961 II 6020261 6032228 11967 9363M1I17M1D7M6D2573M\n",
        "mol-32-ad1c-098478 - 0 8792 8792 II 6021480 6030278 8798 8144M1I17M1D7M6D623M\n",
        "mol-32-ad1c-006971 + 0 8118 8142 II 6021524 6029641 8117 8100M1I17M24S\n",
        "mol-32-ad1c-053939 - 0 12488 12488 II 6022097 6034592 12495 7527M1I17M1D7M6D2492M1D2444M\n",
        "mol-32-ab22-118103 + 0 11761 11761 II 6022171 6033938 11767 7453M1I17M1D7M6D4283M\n",
        "mol-32-ad1c-087799 - 0 10114 10114 II 6022841 6032961 10120 6783M1I17M1D7M6D3306M\n",
        "mol-32-ab22-103841 + 0 5363 5363 II 6024620 6029989 5369 5004M1I17M1D7M6D334M\n",
        "mol-32-ad1c-007737 - 0 6641 6641 II 6024889 6031536 6647 4735M1I17M1D7M6D1881M\n",
        "mol-32-ad1c-042756 - 0 9530 9530 II 6025119 6034655 9536 4505M1I17M1D7M6D5000M\n",
        "mol-32-ad1c-005223 + 0 9560 9560 II 6025226 6034793 9567 4398M1I17M1D7M6D2492M1D2645M\n",
        "mol-32-ad1c-063702 - 0 5564 5564 II 6025278 6030848 5570 4346M1I17M1D7M6D1193M\n",
        "mol-32-ab22-107440 + 0 10189 10189 II 6027086 6037281 10195 2538M1I17M1D7M6D7626M\n",
        "mol-32-ab22-108751 + 0 10225 10225 II 6027756 6037987 10231 1868M1I17M1D7M6D8332M\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filename: utils.py\n",
      "#prepare some functions that can be used globely, such as read the reference to the memory, read the fastq file to dict\n",
      "from Bio import SeqIO\n",
      "def readtodic(fastqfile):\n",
      "    \"\"\"\n",
      "    Give a fastq file name, return a dict contains the name and seq\n",
      "    Require Biopython SeqIO medule to parse the sequence into dict, a large readfile may take a lot of RAM\n",
      "    \"\"\"\n",
      "    handle = open(fastqfile, \"rU\")\n",
      "    record_dict = SeqIO.to_dict(SeqIO.parse(handle, \"fastq\"))\n",
      "    handle.close()\n",
      "    return record_dict\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    read_dict= readtodic(\"../cb12.fq\")\n",
      "    print len(read_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "267885\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "read_dict['mol-32-ab22-000001'].seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "Seq('GAAACCTAGACTTATCAGATGGGCTTTAAAACCTGTAAAAAAGACCCTTTAACT...GCA', SingleLetterAlphabet())"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: get_fasta_realignment.py\n",
      "\n",
      "import cPickle as pickle\n",
      "\n",
      "\"\"\"\n",
      "From the pickle file ,restore the N_list\n",
      "for a position of N_list, get the reads overlap the region, with =-10 flanking region\n",
      "and check the Ns within a length range,\n",
      "give the position and the reads that can possibly overlapped the region\n",
      "take the reads out and make the alignment\n",
      "\"\"\"\n",
      "import cPickle as pickle\n",
      "import pysam\n",
      "\n",
      "def get_readname(samfile_name, chr, start,end):\n",
      "    read_names=[]\n",
      "    with pysam.AlignmentFile(samfile_name) as samfile:\n",
      "        for read in samfile.fetch(chr,start-10,end+10):\n",
      "            read_names.append(read.query_name)\n",
      "    return read_names\n",
      "\n",
      "def chr_select(record_dict, chr, start,end):\n",
      "    \"\"\"\n",
      "    Note the start and end is 0 based\n",
      "    give the name of refdic, and the chr, start and end to be used\n",
      "    return the name and sequence\n",
      "    for example, chrcut(record_dict, \"I\", 0,100) returns\n",
      "    \"\"\"\n",
      "    name=chr+ \":\"+str(start)+\"_\"+str(end)\n",
      "    seq=str(record_dict[chr].seq)[start:end]\n",
      "    return name,seq\n",
      "\n",
      "def write_fasta(samfile_name,ref_dict, read_dict,chr,start,end,out=\"support_read.fasta\"):\n",
      "    \"\"\"\n",
      "    input: a list containing all the read names to be written,\n",
      "           a dictionary containing all the {readname:sequence} in biopython SeqIO format\n",
      "    output:a file\n",
      "    Note: the biopython SeqIO is really toooo complex to be used in writing an simple fasta file\n",
      "    \"\"\"\n",
      "    read_names=get_readname(samfile_name,chr,start,end)\n",
      "    chro,seq=chr_select(ref_dict,chr,start-1000,end+1000)  #have not consider the gap in the beggining or the end of the chrs\n",
      "    with open(out,\"w\") as f:\n",
      "        f.write(\">\")\n",
      "        f.write(str(chro+\":\"+str(start)+\"..\"+str(end)))\n",
      "        f.write(\"\\n\")\n",
      "        f.write(seq)\n",
      "        f.write(\"\\n\")\n",
      "        for name in read_names:\n",
      "            sequence = str(read_dict[name].seq)\n",
      "            f.write(\">\")\n",
      "            f.write(name)\n",
      "            f.write(\"\\n\")\n",
      "            f.write(sequence)\n",
      "            f.write(\"\\n\")\n",
      "                           \n",
      "if __name__ == \"__main__\":\n",
      "    fp=open(\"N_list.dat\",\"rb\")\n",
      "    N_list=pickle.load(fp)\n",
      "    fp.close()\n",
      "    chro,start,end=N_list[1]\n",
      "    print len(N_list)\n",
      "    print chro,start,end\n",
      "    write_fasta(samfile_name=\"cb12i_s.bam\",ref_dict=record_dict, read_dict=read_dict,chr=chro,start=start,end=end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4940\n",
        "V_random 62742 62766\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'read_dict' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-86f91d199b63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mchro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mwrite_fasta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cb12i_s.bam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecord_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'read_dict' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "# retian the function for the alignment\n",
      "mucsle -in support_read.fasta -out out.fas -maxiters 1 -diags1\n",
      "#give a fasta muscle alignment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test.py\n",
      "chro,start,end=N_list[1]\n",
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "for read in samfile.fetch(chro, start, end): #the fetch is like to choose a subset of the bam file within a small region, default is all\n",
      "    print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ab22-094291 + 527 5170 5170 V_random 60602 65269 4667\n",
        "mol-32-ad1c-002101 + 0 4204 4204 V_random 60602 64830 4228\n",
        "mol-32-ad1c-064843 + 1335 9168 9168 V_random 60602 68459 7857\n",
        "mol-32-ab22-042693 - 1251 5866 5866 V_random 60602 65241 4639\n",
        "mol-32-ab22-043686 - 0 5690 5690 V_random 60602 66316 5714\n",
        "mol-32-ad1c-097837 - 3603 9476 9476 V_random 60602 66499 5897\n",
        "mol-32-ab22-119890 + 0 3507 3507 V_random 61480 65011 3531\n",
        "mol-32-ab22-124895 - 0 2526 2526 V_random 61898 64449 2551\n",
        "mol-32-ab22-110910 - 0 8588 8588 V_random 62349 70961 8612\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test.py\n",
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "for read in samfile.fetch('III', 1834312, 1835336): #the fetch is like to choose a subset of the bam file within a small region, default is all\n",
      "    print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ad1c-108511 + 0 5004 6207 III 1830059 1834313 4254\n",
        "mol-32-ab22-005231 - 0 4500 4829 III 1830563 1834313 3750\n",
        "mol-32-ad1c-068974 - 0 4098 4435 III 1830965 1834313 3348\n",
        "mol-32-ab22-050876 + 0 3972 4052 III 1831091 1834313 3222\n",
        "mol-32-ad1c-051754 + 839 2882 3103 III 1832269 1834313 2044\n",
        "mol-32-ab22-007076 - 64 2107 2330 III 1832269 1834313 2044\n",
        "mol-32-ad1c-033129 + 0 1467 1682 III 1832846 1834313 1467\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to get per base coverage at a place\n",
      "# the str of the pileup function\n",
      "# Class: AlignmentFile.pileup.pileups\n",
      "# Classname: AlignmentFile.pileup==pileupcolumn; AlignmentFile.pileup.pileups==pileupread\n",
      "# Note: the N_list do not include the end of the gap region, so is needed to be expanded\n",
      "\n",
      "#filename: cons.py\n",
      "#Given a consesune matrix, get the cons from the sequence, used to find the replacement of the gapped \"N\"s\n",
      "\n",
      "#todo: change the marix tp pandas or nympy object\n",
      "#todo: can add a function to convert the \n",
      "\n",
      "import pysam\n",
      "\n",
      "def con_sequence(samfile,chro,start,end):\n",
      "    \"\"\"\n",
      "    Input: the opened pysam.Alignmentfile, and a bed interval\n",
      "    Out: get the read matrix in a dict\n",
      "    \"\"\"\n",
      "    cons_list={}\n",
      "    n=0\n",
      "    #take 5 mer 5' and 3' flanking sequence together with N as the input\n",
      "    for pileupcolumn in samfile.pileup(chro,start-5,end+5, truncate=True):\n",
      "        \n",
      "        site_seq=\"\"  # to avoid some UnboundLocalError in python 2.7, give an init value firstly\n",
      "        \n",
      "        for pileupread in pileupcolumn.pileups:\n",
      "            \n",
      "            if n==0: # init the first containers\n",
      "                cons_list[str(pileupread.alignment.query_name)]=[]\n",
      "            \n",
      "            if pileupread.indel>0:  # for insertion\n",
      "                site_seq=pileupread.alignment.query_sequence[pileupread.query_position:(pileupread.query_position+pileupread.indel+1)]\n",
      "            if pileupread.is_del:  # for deletion\n",
      "                site_seq=\"-\" \n",
      "            else:\n",
      "                if pileupread.indel==0:  # for 1:1 matched nuclitide\n",
      "                    site_seq=pileupread.alignment.query_sequence[pileupread.query_position]\n",
      "                if pileupread.indel<0:  # for the insertion nucl followed by a deletion, should be treated as the 1:1 matched\n",
      "                    site_seq=pileupread.alignment.query_sequence[pileupread.query_position]\n",
      "                    \n",
      "            #  need to add some new read to the dict, add more containers\n",
      "            try: \n",
      "                cons_list[str(pileupread.alignment.query_name)].extend(list(site_seq))\n",
      "                con_length=len(cons_list[str(pileupread.alignment.query_name)])\n",
      "            except KeyError:\n",
      "                cons_list[str(pileupread.alignment.query_name)]=[\"0\"]*(con_length-1)  # the current one has not been popped,so need a -1\n",
      "                cons_list[str(pileupread.alignment.query_name)].extend(list(site_seq))\n",
      "        n+=1  # n stand for the nucl number of the reference, not the matrix\n",
      "        \n",
      "        # Test code for the length of the cons_list\n",
      "    #print chro,start,end\n",
      "    return cons_list\n",
      "\n",
      "\n",
      "def con_matrix(cons_list):\n",
      "    \"\"\"\n",
      "    the samfile should be opened outside the function to avoid too much I/O\n",
      "    from the same region of the bam file, get all the sequence from read for each position\n",
      "    return 5 list: ATGC DEL\n",
      "    \"\"\"\n",
      "    try:\n",
      "        gaplength=len(cons_list.values()[0])\n",
      "        \n",
      "        A=[0]*gaplength\n",
      "        C=[0]*gaplength\n",
      "        G=[0]*gaplength\n",
      "        T=[0]*gaplength\n",
      "        DEL=[0]*gaplength\n",
      "    \n",
      "        for seq in cons_list.values():\n",
      "            for n in range(0,len(seq)):\n",
      "                if seq[n] in \"Aa\":\n",
      "                    A[n]+=1\n",
      "                if seq[n] in \"Cc\":\n",
      "                    C[n]+=1\n",
      "                if seq[n] in \"Gg\":\n",
      "                    G[n]+=1\n",
      "                if seq[n] in \"Tt\":\n",
      "                    T[n]+=1\n",
      "                if seq[n]==\"-\":\n",
      "                    DEL[n]+=1\n",
      "    # if the dict is empty, then make some empty lists directly\n",
      "    except IndexError:\n",
      "        gaplength=0\n",
      "        A=[0]*gaplength\n",
      "        C=[0]*gaplength\n",
      "        G=[0]*gaplength\n",
      "        T=[0]*gaplength\n",
      "        DEL=[0]*gaplength\n",
      "        \n",
      "    return (DEL,A,C,G,T)\n",
      "\n",
      "def cons(DEL,A,C,G,T):\n",
      "    \"\"\"\n",
      "    Given: five list contains the DEL,A,C,G,T frenqency\n",
      "    Return: the consensus string of the matrix\n",
      "    \"\"\"\n",
      "    cons_string=[]\n",
      "    for i in range(0,len(A)):\n",
      "        col={\"-\":DEL[i],\"A\":A[i], \"C\":C[i], \"G\":G[i], \"T\":T[i]}\n",
      "        #design model: search\n",
      "        max_n=max(col.values())\n",
      "        if max_n==0:  # avoid no coverage status\n",
      "            pass\n",
      "        else: \n",
      "            for key in col.keys():\n",
      "                if col[key]==max_n:\n",
      "                    cons_string.append(key)\n",
      "                    #just take the first as best\n",
      "                    break\n",
      "                    #count+=1\n",
      "                #if count>1:\n",
      "                    #print \"Dupilicated best!\"\n",
      "    return \"\".join(cons_string)\n",
      "\n",
      "def write_nreplace():\n",
      "    # main code\n",
      "    with open(\"N_text.txt\",\"w\") as f:\n",
      "        for N_single in N_list:\n",
      "            #print N_single\n",
      "            chro, start,end =N_single\n",
      "            \n",
      "            matrix=con_matrix(con_sequence(samfile, chro,start,end+1))\n",
      "            DEL,A,C,G,T=matrix\n",
      "            sequence=cons(DEL,A,C,G,T)\n",
      "            \n",
      "            name,seq_raw=chr_select(record_dict, chro,start-5,end+1+5)\n",
      "            \n",
      "            f.write(name)\n",
      "            f.write(\"\\t\")\n",
      "            f.write(seq_raw)\n",
      "            f.write(\"\\t\")\n",
      "            f.write(sequence)\n",
      "            f.write(\"\\n\")\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "    #test code\n",
      "    N_list_new=N_list[264:265]\n",
      "    for N_single in N_list_new:\n",
      "        print N_single\n",
      "        chro, start,end =N_single\n",
      "        aa=con_sequence(samfile, chro,start,end+1)\n",
      "        bb=con_matrix(aa)\n",
      "        DEL,A,C,G,T=bb\n",
      "        sequence=cons(DEL,A,C,G,T)\n",
      "        print sequence\n",
      "    \n",
      "    write_nreplace()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('I', 4237283, 4237285)\n",
        "ACCCGCG-CGATT\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# replace the sequence from the raw sequence into the new sequence\n",
      "# the output is a file in lines like: ('I', '694217', '694228', 'GCTGGNCTATG', 'GCTGGTCTATG')==chr,start,end,seq_raw,seq_new, seperated by \\t\n",
      "def parse_nline(line):\n",
      "    name=line.split(\"\\t\")[0]\n",
      "    seq_raw=line.split(\"\\t\")[1].upper()\n",
      "    \n",
      "    # using \"\" as last element of empty seq_new\n",
      "    try:\n",
      "        seq_new=line.split(\"\\t\")[2].strip().upper()\n",
      "    except Exception:\n",
      "        seq_new=\"\"\n",
      "    return name, seq_raw,seq_new\n",
      "    \n",
      "def parse_nname(name):\n",
      "    chro=name.split(\":\")[0]\n",
      "    start=name.split(\":\")[1].split(\"_\")[0]\n",
      "    end=name.split(\":\")[1].split(\"_\")[1]\n",
      "    return chro,start,end\n",
      "\n",
      "def read_nreplace(N_test_filename=\"N_text.txt\"):\n",
      "    f=open(N_test_filename)\n",
      "    \n",
      "    N_replace=[]\n",
      "    n_1=0 \n",
      "    len_1=0\n",
      "    \n",
      "    for line in f.readlines():\n",
      "        name,seq_raw,seq_new = parse_nline(line)\n",
      "        \n",
      "        # Jduge the insertion credibility by 3 para: the first 5 nucls, the last 5 nucls and the length of the consensus\n",
      "        \n",
      "        # 1. \"Filled\", The perfect match of the sequence, the most easy way to add in\n",
      "        if seq_raw[:5]==seq_new[:5] and seq_raw[-5:]==seq_new[-5:] and len(seq_new)>=len(seq_raw):\n",
      "            # some status\n",
      "            n_1+=1\n",
      "            len_1+=len(seq_raw)\n",
      "            \n",
      "            chro,start,end=parse_nname(name)\n",
      "            N_single=(chro, start, end, seq_raw, seq_new)\n",
      "            N_replace.append(N_single)\n",
      "            # some result to be known\n",
      "            \n",
      "        # 2. \" Double extented or Possible double bp\", The perfect match of the flanking sequence, so if there are some unalign end, the end can be used to extened \n",
      "        #     the gap or used to direct the region to other place (so called bp), \n",
      "        #     at this time , the seq_new is almost 10 (with some edge not well aligned, so length usually +-1)\n",
      "        #  ignore at this time\n",
      "        #if seq_raw[:5]==seq_new[:5] and seq_raw[-5:]==seq_new[-5:] and len(seq_new)<len(seq_raw):\n",
      "        #    if len(seq_new) <14:  #all length is less than 14\n",
      "                #print name,seq_raw,seq_new,len(seq_raw),len(seq_new)\n",
      "                \n",
      "        # 3. \"Single extended\" or \"single breakpoint\"\n",
      "            # ignored at this time\n",
      "            \n",
      "    print \"In total, %d gaps with %d bps were recorded to be filled.\" % (n_1,len_1)  \n",
      "        \n",
      "    f.close()\n",
      "    return N_replace\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    N_replace=read_nreplace(N_test_filename=\"N_text.txt\")\n",
      "    print N_replace[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "In total, 1046 gaps with 109962 bps were recorded to be filled.\n",
        "('I', '694217', '694228', 'GCTGGNCTATG', 'GCTGGTCTATG')\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sequence_replace(record_dict=record_dict, N_replace=read_nreplace(N_test_filename=\"N_text.txt\"),outfile=\"replaced.fasta\" ):\n",
      "    \"\"\"\n",
      "    @para refdic: the reference name and sequence in dict format\n",
      "    @para N_test_filename, the \"N_text.txt\" file, generated by the previous function\n",
      "    @para outfile, the filename to be written with the replaced fasta file\n",
      "    \"\"\"\n",
      "    fw=open(outfile,\"w\")\n",
      "    \n",
      "    for name in record_dict.keys():\n",
      "        print name\n",
      "        # the orign sequence, all in upper\n",
      "        seq_chro=str(record_dict[name].seq).upper()\n",
      "        \n",
      "        # get fill inormation for one chr\n",
      "        subreplace={}\n",
      "        for N_single in N_replace:\n",
      "            chro, start, end, seq_raw, seq_new=N_single\n",
      "            if name==chro:\n",
      "                subreplace[(int(start),int(end))]=N_single\n",
      "        # get the start and end, change them to int and sort\n",
      "        cutsite=[]\n",
      "        for key in subreplace.keys():\n",
      "            chro, start, end, seq_raw, seq_new=subreplace[key]\n",
      "            cutsite.append((int(start),int(end)))\n",
      "        cutsite.sort()\n",
      "        print \"Total %d gaps filled for this chro\" % len(cutsite)\n",
      "        \n",
      "        seq_chro_new=[]\n",
      "        for i in range(0,len(cutsite)): \n",
      "            #start \n",
      "            if i==0:\n",
      "                i_start,i_end=cutsite[i]\n",
      "                seq_1=seq_chro[:i_start]\n",
      "                \n",
      "                seq_2_chro=seq_chro[i_start:i_end]\n",
      "                seq_2_raw=subreplace[(i_start,i_end)][3]\n",
      "                \n",
      "                seq_2_new=subreplace[i_start,i_end][4]\n",
      "                \n",
      "                if seq_2_chro==seq_2_raw:\n",
      "                    seq_chro_new.append(seq_1)\n",
      "                    seq_chro_new.append(seq_2_new)\n",
      "                else:\n",
      "                    print \"Unequal length of stored gap and actual gap position, check the reference sequence!\"\n",
      "\n",
      "            #common\n",
      "            if i!=0:\n",
      "                i_start,i_end=cutsite[i-1]\n",
      "                i2_start,i2_end=cutsite[i]\n",
      "        \n",
      "                seq_1=seq_chro[i_end:i2_start]\n",
      "                \n",
      "                seq_2_chro=seq_chro[i2_start:i2_end]\n",
      "                seq_2_raw=subreplace[(i2_start,i2_end)][3]\n",
      "\n",
      "                seq_2_new=subreplace[i2_start,i2_end][4]\n",
      "                \n",
      "                if seq_2_chro==seq_2_raw:\n",
      "                    seq_chro_new.append(seq_1)\n",
      "                    seq_chro_new.append(seq_2_new)\n",
      "                else:\n",
      "                    print \"Unequal length of stored gap and actual gap position, check the reference sequence!\"\n",
      "            #end\n",
      "            if i==len(cutsite)-1:\n",
      "                i_start,i_end=cutsite[i]\n",
      "                seq_1=seq_chro[i_end:]\n",
      "                \n",
      "                seq_chro_new.append(seq_1)\n",
      "\n",
      "        # the deletions is still in \"-\", remove them\n",
      "        seq_chro_new_str=\"\".join(seq_chro_new).replace(\"-\",\"\")\n",
      "        \n",
      "        # for a chr without N sites        \n",
      "        if cutsite==[]:\n",
      "            seq_chro_new_str=seq_chro\n",
      "            \n",
      "        print \"Length after fill: %d; length before fill: %d.\" % (len(seq_chro_new_str), len(seq_chro))\n",
      "        \n",
      "        # write the sequence\n",
      "        fw.write(\">\")\n",
      "        fw.write(name)\n",
      "        fw.write(\"\\n\")\n",
      "        fw.write(seq_chro_new_str)\n",
      "        fw.write(\"\\n\")\n",
      "        \n",
      "    fw.close()\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    sequence_replace()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "In total, 1046 gaps with 109962 bps were recorded to be filled.\n",
        "V_random\n",
        "Total 1 gaps filled for this chro\n",
        "Length after fill: 87168; length before fill: 87193.\n",
        "III_random\n",
        "Total 0 gaps filled for this chro\n",
        "Length after fill: 106014; length before fill: 106014.\n",
        "I\n",
        "Total 186 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 15487200; length before fill: 15502796.\n",
        "I_random\n",
        "Total 2 gaps filled for this chro\n",
        "Length after fill: 46294; length before fill: 46295.\n",
        "IV\n",
        "Total 205 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 17528103; length before fill: 17542550.\n",
        "II"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total 145 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 16640450; length before fill: 16649854.\n",
        "un\n",
        "Total 88 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 3109364; length before fill: 3109756.\n",
        "V\n",
        "Total 185 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 19544259; length before fill: 19557073.\n",
        "X"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total 93 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 21544986; length before fill: 21552363.\n",
        "III"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total 141 gaps filled for this chro"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Length after fill: 14570207; length before fill: 14584305.\n",
        "IV_random\n",
        "Total 0 gaps filled for this chro\n",
        "Length after fill: 24778; length before fill: 24778.\n",
        "X_random\n",
        "Total 0 gaps filled for this chro\n",
        "Length after fill: 28673; length before fill: 28673.\n"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        for i in range(0,len(cutsite)):\n",
      "            if i==0:\n",
      "                i_start,i_end=cutsite[i]\n",
      "                start=0\n",
      "                end=i_start\n",
      "            if i==len(cutsite):\n",
      "                i_start,i_end=cutsite[i]\n",
      "                start=i_end\n",
      "                end=len(seq_old)\n",
      "            else:\n",
      "                i_start,i_end=cutsite[i-1]\n",
      "                i2_start,i2_end=cutsite[i]\n",
      "                start=i_end\n",
      "                end=i2_start\n",
      "            sub_segment.append\n",
      "\n",
      "\n",
      "import time\n",
      "a=time.clock()\n",
      "for i in range(1,1000000):\n",
      "    for n in range(1,1000):\n",
      "        pass\n",
      "b=time.clock()\n",
      "\n",
      "print b-a\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "48.41\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__==\"__main__\":\n",
      "    samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "    with open(\"N_text.txt\",\"w\") as f:\n",
      "        for N_single in N_list:\n",
      "            #print N_single\n",
      "            chro, start,end =N_single\n",
      "            DEL,A,C,G,T=con_matrix(samfile, chro,start,end+1)\n",
      "            sequence=cons(DEL,A,C,G,T)\n",
      "            f.write(str(chr_select(record_dict, chro,start,end+1)))\n",
      "            f.write(\"\\t\")\n",
      "            f.write(sequence)\n",
      "            f.write(\"\\n\")\n",
      "    samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "('V_random', 62742, 62766)"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#test.py\n",
      "for pileupcolumn in samfile.pileup(chro,start,end+1, truncate=True):\n",
      "    print (\"\\ncoverage at base %s = %s\" %\n",
      "            (pileupcolumn.pos, pileupcolumn.n))\n",
      "    for pileupread in pileupcolumn.pileups:\n",
      "        print pileupread.alignment.query_sequence[pileupread.query_position]\n",
      "        print pileupread.is_del  #if this position is a deletion,then the replacemnet can be ignored\n",
      "        print pileupread.indel\n",
      "\n",
      "# the test code for main\n",
      "    print N_list[19]\n",
      "    chro, start,end =N_list[19]\n",
      "    print chr_select(record_dict, chro,start,end+1)\n",
      "    \n",
      "    samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "    DEL,A,C,G,T=con_matrix(samfile, chro,start,end+1)\n",
      "    aa=cons(DEL,A,C,G,T)\n",
      "    print aa\n",
      "    print len(aa)\n",
      "    print end+1-start\n",
      "    samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "I/O operation on closed file",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-67-ce3e691234f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#test.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpileupcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpileup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     print (\"\\ncoverage at base %s = %s\" %\n\u001b[0;32m      4\u001b[0m             (pileupcolumn.pos, pileupcolumn.n))\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpileupread\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpileupcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpileups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pysam/calignmentfile.so\u001b[0m in \u001b[0;36mpysam.calignmentfile.AlignmentFile.pileup (pysam/calignmentfile.c:10696)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "\n",
      "for N_single in N_list:\n",
      "    chro, start,end=N_single\n",
      "    if end-start>24:\n",
      "        print \"T\"\n",
      "        for pileupcolumn in samfile.pileup(chro,start,end+1, truncate=True):\n",
      "            print (\"\\ncoverage at base %s = %s\" % (pileupcolumn.pos, pileupcolumn.n))\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-6-88f4df480ae1>, line 11)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-88f4df480ae1>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    samfile.close()\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: bam2coverage.py\n",
      "# from bam file get the coverage as\n",
      "# the following is the test code\n",
      "\n",
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\" )\n",
      "for pileupcolumn in samfile.pileup(\"II\",6029640,6029655):\n",
      "    if pileupcolumn.pos in range(6029640,6029655+1):\n",
      "        print (\"\\ncoverage at base %s = %s\" %\n",
      "                (pileupcolumn.pos, pileupcolumn.n))\n",
      "        for pileupread in pileupcolumn.pileups:\n",
      "            print pileupread.query_position,\n",
      "            print pileupread.indel\n",
      "            print ('\\tbase in read %s = %s' %\n",
      "                    (pileupread.alignment.query_name,\n",
      "                     pileupread.alignment.query_sequence[pileupread.query_position]))\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pysama",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-39-f0f61380c002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# from bam file get the coverage as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# the following is the test code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpysama\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msamfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cb12i_s.bam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpileupcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpileup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"II\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6029640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6029655\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named pysama"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "muscle -in support_read.fasta -out aaaaa.html  -diags -maxiters 1 -html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "aaaaa.html                      cb4_insertion_filled.fasta.bwt  nfill.ipynb\r\n",
        "cb12i_s.bam                     cb4_insertion_filled.fasta.fai  N_list.dat\r\n",
        "cb12i_s.bam.bai                 cb4_insertion_filled.fasta.pac  N_list.db\r\n",
        "cb4_insertion_filled.fasta      cb4_insertion_filled.fasta.sa   N_text.txt\r\n",
        "cb4_insertion_filled.fasta.amb  nfill-Copy0.ipynb\r\n",
        "cb4_insertion_filled.fasta.ann  nfill-Copy1.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fill_N(record_dict, N_list):\n",
      "    for n_range in N_list:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}