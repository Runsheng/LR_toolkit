{
 "metadata": {
  "name": "",
  "signature": "sha256:257aefcd0024337894b568b04636482f0f67c6002068a2385d77bedfd530604f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../3st_inserted_mapping/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/li/new/data/cb/3st_inserted_mapping\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###  Consider several possibility of the \"Ns\"(or rather *gaps*)\n",
      "#### 1. the \"Ns\" can be coverd by single read, the Ns can be recovered as mismatches and be replaced, this should be most of the case for the samll gaps.\n",
      "- Something has to be noted, the read has a high (0.1%, compared to the less than 0.01% mismatch and insertion) rate of deletion, so if a samll indel was found to be in a \"deletion region\" of the long read, the deletion should be ignored, and the gap region should be remained.\n",
      "- This can be further confirmed by TRfinder, in this case, this region should be masked by tandem repeat finder, if the region is full of tandem repetor, this singnal should be igored.\n",
      "\n",
      "#### 2. the \"Ns\" cause some **unaligned end**: find the begin and the end, make realignment with some aligner(bwa?muscle?), and give the Ns some repalcements, and fill the \"Ns\". When parsing the unaligned ends, some situations should be treated differently:\n",
      "- No read support --> ignore, unfilled\n",
      "- Unaligned end in both direction\n",
      "  - unalign end overlapped at the end --> filled, caculated the length of the read\n",
      "  - unalign end do not overlap --> double extended, unfilled\n",
      "- Unaligned end in one direction\n",
      "  - align with the beginning of the other edge (for example, 500bp?)\n",
      "    - unalign end overlapped with the beginning of the other edge --> filled\n",
      "    - unalign end do not overlap --> single extended, unfilled\n",
      "\n",
      "#### 3. How long flaking sequence shold the be used?\n",
      "- 200bp? 50bp? 20bp? For the alignment 200bp is long enough, and the pileup of samfiles can indicate the edge of the right mapping\n",
      "\n",
      "#### 4.Keep in mind that the filling of Ns is used for the precise break point detection\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#fillname: summary_N.py\n",
      "\n",
      "from Bio import SeqIO\n",
      "import cPickle as pickle\n",
      "\n",
      "def reftodic(fastafile):\n",
      "    \"\"\"\n",
      "    Give a fasta file name, return a dict contains the name and seq\n",
      "    Require Biopython SeqIO medule to parse the sequence into dict, a large genome may take a lot of RAM\n",
      "    \"\"\"\n",
      "    handle = open(fastafile, \"rU\")\n",
      "    record_dict = SeqIO.to_dict(SeqIO.parse(handle, \"fasta\"))\n",
      "    handle.close()\n",
      "    return record_dict\n",
      "\n",
      "def summary_N(record_dict, N_threshold=5):\n",
      "    \"\"\"\n",
      "    Give a function to summary the \"N\"s in the genome, and return a bed like tuple-list to describe the \"N\"s,\n",
      "    Output tuple format: (\"chr\", str,end). chr is type(str), while start and end is type(int)\n",
      "    Note: the hard-masked genome will be regonized as gap\n",
      "    \"\"\"\n",
      "    N_list=[]\n",
      "    for chr in record_dict.keys():\n",
      "        seq=str(record_dict[chr].seq).lower()\n",
      "        left=[]\n",
      "        right=[]\n",
      "        for i,nucl in enumerate(list(seq)):\n",
      "            if nucl==\"n\" and seq[(i-1)]!=\"n\":\n",
      "                left.append(i)\n",
      "            #the right edge can be the end of the chr, then n+1 will raise an error\n",
      "            try:\n",
      "                if nucl==\"n\" and seq[(i+1)]!=\"n\":\n",
      "                    right.append(i)\n",
      "            except Exception:\n",
      "                pass\n",
      "            if i==len(seq) and nucl==\"n\":\n",
      "                right.append(i)\n",
      "        # check if the left edge and right edge are paired. Normally it should be OK.\n",
      "        if len(left)==len(right):\n",
      "            count=0\n",
      "            length_N=0\n",
      "            for i in range(0,len(left)):\n",
      "                N_single=(chr,left[i],right[i])\n",
      "                N_list.append(N_single)\n",
      "                # print some stat out\n",
      "                length_N+=right[i]-left[i]+1\n",
      "                if right[i]-left[i]>=N_threshold:\n",
      "                    count+=1\n",
      "            print \"%s has %d gaps (len> %d bp), total gap length is %d (single N included).\" %(chr,count,N_threshold,length_N)\n",
      "        else:\n",
      "            print \"left\", len(left), \"unequal to\", \"right\", len(right)\n",
      "    #store the N_list as pickle file\n",
      "    with open(\"N_list.dat\",\"wb\") as fp:\n",
      "        pickle.dump(N_list, fp)\n",
      "    return N_list\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "    record_dict=reftodic(\"cb4_insertion_filled.fasta\")\n",
      "    aa=summary_N(record_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "V_random has 2 gaps (len> 5 bp), total gap length is 70 (single N included).\n",
        "III_random has 3 gaps (len> 5 bp), total gap length is 6220 (single N included).\n",
        "I has 472 gaps (len> 5 bp), total gap length is 301715 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "I_random has 2 gaps (len> 5 bp), total gap length is 111 (single N included).\n",
        "IV has 503 gaps (len> 5 bp), total gap length is 381080 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "II has 478 gaps (len> 5 bp), total gap length is 428202 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "un has 554 gaps (len> 5 bp), total gap length is 79461 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "V has 484 gaps (len> 5 bp), total gap length is 342172 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "X has 315 gaps (len> 5 bp), total gap length is 331692 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "III has 380 gaps (len> 5 bp), total gap length is 271645 (single N included)."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "IV_random has 1 gaps (len> 5 bp), total gap length is 1462 (single N included).\n",
        "X_random has 0 gaps (len> 5 bp), total gap length is 1 (single N included).\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: check_N.py\n",
      "# restore the database\n",
      "\"\"\"\n",
      "From the pickle file ,restore the N_list\n",
      "and check the Ns within a length range, \n",
      "give the position and the reads that can possibly overlapped the region\n",
      "take the reads from the \n",
      "\"\"\"\n",
      "try: \n",
      "    import cPickle as pickle\n",
      "except Exception:\n",
      "    import pickle as pickle\n",
      "import pysam\n",
      "\n",
      "with open(\"N_list.dat\",\"rb\") as fp:\n",
      "    N_list=pickle.load(fp)\n",
      "    for i in range(1000,2000):\n",
      "        if 10000<N_list[i][2]-N_list[i][1]:\n",
      "            print N_list[i]\n",
      "            chr,start,end=N_list[i]\n",
      "            with pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\") as samfile:\n",
      "                for read in samfile.fetch(chr,start-10,end+10):\n",
      "                    print read.query_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('IV', 3813084, 3827854)\n",
        "mol-32-ab22-022434\n",
        "mol-32-ad1c-064079\n",
        "mol-32-ad1c-025487\n",
        "mol-32-ab22-056006\n",
        "mol-32-ad1c-023255\n",
        "mol-32-ab22-135286\n",
        "mol-32-ad1c-023255\n",
        "('IV', 12592468, 12605466)\n",
        "('IV', 16815074, 16832983)\n",
        "('II', 3691251, 3702042)\n",
        "mol-32-ad1c-023617\n",
        "mol-32-ab22-109541\n",
        "mol-32-ad1c-083720\n",
        "mol-32-ad1c-128917\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#use the n position, to fill n with the mapped long reads\n",
      "import pysam\n",
      "with pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\") as samfile:\n",
      "    for read in samfile.fetch(\"II\",6029640,6029655): \n",
      "        print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length, read.cigarstring"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ad1c-022195 + 0 12685 12685 II 6019032 6031723 12691 10592M1I17M1D7M6D2068M\n",
        "mol-32-ab22-063362 + 0 11624 11624 II 6019453 6031083 11630 10171M1I17M1D7M6D1428M\n",
        "mol-32-ab22-088824 - 0 10428 10428 II 6019558 6029992 10434 10066M1I17M1D7M6D337M\n",
        "mol-32-ad1c-115785 + 0 10590 10590 II 6019770 6030366 10596 9854M1I17M1D7M6D711M\n",
        "mol-32-ab22-119095 - 0 11961 11961 II 6020261 6032228 11967 9363M1I17M1D7M6D2573M\n",
        "mol-32-ad1c-098478 - 0 8792 8792 II 6021480 6030278 8798 8144M1I17M1D7M6D623M\n",
        "mol-32-ad1c-006971 + 0 8118 8142 II 6021524 6029641 8117 8100M1I17M24S\n",
        "mol-32-ad1c-053939 - 0 12488 12488 II 6022097 6034592 12495 7527M1I17M1D7M6D2492M1D2444M\n",
        "mol-32-ab22-118103 + 0 11761 11761 II 6022171 6033938 11767 7453M1I17M1D7M6D4283M\n",
        "mol-32-ad1c-087799 - 0 10114 10114 II 6022841 6032961 10120 6783M1I17M1D7M6D3306M\n",
        "mol-32-ab22-103841 + 0 5363 5363 II 6024620 6029989 5369 5004M1I17M1D7M6D334M\n",
        "mol-32-ad1c-007737 - 0 6641 6641 II 6024889 6031536 6647 4735M1I17M1D7M6D1881M\n",
        "mol-32-ad1c-042756 - 0 9530 9530 II 6025119 6034655 9536 4505M1I17M1D7M6D5000M\n",
        "mol-32-ad1c-005223 + 0 9560 9560 II 6025226 6034793 9567 4398M1I17M1D7M6D2492M1D2645M\n",
        "mol-32-ad1c-063702 - 0 5564 5564 II 6025278 6030848 5570 4346M1I17M1D7M6D1193M\n",
        "mol-32-ab22-107440 + 0 10189 10189 II 6027086 6037281 10195 2538M1I17M1D7M6D7626M\n",
        "mol-32-ab22-108751 + 0 10225 10225 II 6027756 6037987 10231 1868M1I17M1D7M6D8332M\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filename: utils.py\n",
      "#prepare some functions that can be used globely, such as read the reference to the memory, read the fastq file to dict\n",
      "from Bio import SeqIO\n",
      "def readtodic(fastqfile):\n",
      "    \"\"\"\n",
      "    Give a fastq file name, return a dict contains the name and seq\n",
      "    Require Biopython SeqIO medule to parse the sequence into dict, a large readfile may take a lot of RAM\n",
      "    \"\"\"\n",
      "    handle = open(fastqfile, \"rU\")\n",
      "    record_dict = SeqIO.to_dict(SeqIO.parse(handle, \"fastq\"))\n",
      "    handle.close()\n",
      "    return record_dict\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    read_dict= readtodic(\"../cb12.fq\")\n",
      "    print len(read_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "267885\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "read_dict['mol-32-ab22-000001'].seq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "Seq('GAAACCTAGACTTATCAGATGGGCTTTAAAACCTGTAAAAAAGACCCTTTAACT...GCA', SingleLetterAlphabet())"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: check_N.py\n",
      "# restore the database\n",
      "import cPickle as pickle\n",
      "\n",
      "\"\"\"\n",
      "From the pickle file ,restore the N_list\n",
      "\n",
      "for a position of N_list, get the reads overlap the region, with =-10 flanking region\n",
      "\n",
      "and check the Ns within a length range,\n",
      "give the position and the reads that can possibly overlapped the region\n",
      "take the reads out and make the alignment\n",
      "\"\"\"\n",
      "import cPickle as pickle\n",
      "import pysam\n",
      "\n",
      "def get_readname(samfile_name, chr, start,end):\n",
      "    read_names=[]\n",
      "    with pysam.AlignmentFile(samfile_name) as samfile:\n",
      "        for read in samfile.fetch(chr,start-10,end+10):\n",
      "            read_names.append(read.query_name)\n",
      "    return read_names\n",
      "\n",
      "def chr_select(record_dict, chr, start,end):\n",
      "    \"\"\"\n",
      "    Note the start and end is 0 based\n",
      "    give the name of refdic, and the chr, start and end to be used\n",
      "    return the name and sequence\n",
      "    for example, chrcut(record_dict, \"I\", 0,100) returns\n",
      "    \"\"\"\n",
      "    name=chr+ \":\"+str(start)+\"_\"+str(end)\n",
      "    seq=str(record_dict[chr].seq)[start:end]\n",
      "    return name,seq\n",
      "\n",
      "def write_fasta(samfile_name,ref_dict, read_dict,chr,start,end,out=\"support_read.fasta\"):\n",
      "    \"\"\"\n",
      "    input: a list containing all the read names to be written,\n",
      "           a dictionary containing all the {readname:sequence} in biopython SeqIO format\n",
      "    output:a file\n",
      "    Note: the biopython SeqIO is really toooo complex to be used in writing an simple fasta file\n",
      "    \"\"\"\n",
      "    read_names=get_readname(samfile_name,chr,start,end)\n",
      "    chro,seq=chr_select(ref_dict,chr,start-1000,end+1000)  #have not consider the gap in the beggining or the end of the chrs\n",
      "    with open(out,\"w\") as f:\n",
      "        f.write(\">\")\n",
      "        f.write(str(chro+\":\"+str(start)+\"..\"+str(end)))\n",
      "        f.write(\"\\n\")\n",
      "        f.write(seq)\n",
      "        f.write(\"\\n\")\n",
      "        for name in read_names:\n",
      "            sequence = str(read_dict[name].seq)\n",
      "            f.write(\">\")\n",
      "            f.write(name)\n",
      "            f.write(\"\\n\")\n",
      "            f.write(sequence)\n",
      "            f.write(\"\\n\")\n",
      "                           \n",
      "if __name__ == \"__main__\":\n",
      "    fp=open(\"N_list.dat\",\"rb\")\n",
      "    N_list=pickle.load(fp)\n",
      "    fp.close()\n",
      "    chro,start,end=N_list[1]\n",
      "    print len(N_list)\n",
      "    print chro,start,end\n",
      "    write_fasta(samfile_name=\"cb12i_s.bam\",ref_dict=record_dict, read_dict=read_dict,chr=chro,start=start,end=end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4940\n",
        "V_random 62742 62766\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'read_dict' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-37b98f5d5de0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mchro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mwrite_fasta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"cb12i_s.bam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mref_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecord_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchro\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'read_dict' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "mucsle -in support_read.fasta -out out.fas -maxiters 1 -diags1\n",
      "#give a fasta muscle alignment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chro,start,end=N_list[1]\n",
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "for read in samfile.fetch(chro, start, end): #the fetch is like to choose a subset of the bam file within a small region, default is all\n",
      "    print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ab22-094291 + 527 5170 5170 V_random 60602 65269 4667\n",
        "mol-32-ad1c-002101 + 0 4204 4204 V_random 60602 64830 4228\n",
        "mol-32-ad1c-064843 + 1335 9168 9168 V_random 60602 68459 7857\n",
        "mol-32-ab22-042693 - 1251 5866 5866 V_random 60602 65241 4639\n",
        "mol-32-ab22-043686 - 0 5690 5690 V_random 60602 66316 5714\n",
        "mol-32-ad1c-097837 - 3603 9476 9476 V_random 60602 66499 5897\n",
        "mol-32-ab22-119890 + 0 3507 3507 V_random 61480 65011 3531\n",
        "mol-32-ab22-124895 - 0 2526 2526 V_random 61898 64449 2551\n",
        "mol-32-ab22-110910 - 0 8588 8588 V_random 62349 70961 8612\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "for read in samfile.fetch('III', 1834312, 1835336): #the fetch is like to choose a subset of the bam file within a small region, default is all\n",
      "    print read.query_name,'-' if read.is_reverse else '+',read.query_alignment_start,read.query_alignment_end,read.infer_query_length(),\\\n",
      "          samfile.getrname(read.reference_id), read.reference_start,read.reference_end,read.reference_length\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mol-32-ad1c-108511 + 0 5004 6207 III 1830059 1834313 4254\n",
        "mol-32-ab22-005231 - 0 4500 4829 III 1830563 1834313 3750\n",
        "mol-32-ad1c-068974 - 0 4098 4435 III 1830965 1834313 3348\n",
        "mol-32-ab22-050876 + 0 3972 4052 III 1831091 1834313 3222\n",
        "mol-32-ad1c-051754 + 839 2882 3103 III 1832269 1834313 2044\n",
        "mol-32-ab22-007076 - 64 2107 2330 III 1832269 1834313 2044\n",
        "mol-32-ad1c-033129 + 0 1467 1682 III 1832846 1834313 1467\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to get per base coverage at a place\n",
      "# the str of the pileup function\n",
      "# Class: AlignmentFile.pileup.pileups\n",
      "# Classname: AlignmentFile.pileup==pileupcolumn; AlignmentFile.pileup.pileups==pileupread\n",
      "# Note: the N_list do not include the end of the gap region, so is needed to be expanded\n",
      "\n",
      "#filename: cons.py\n",
      "#Given a consesune matrix, get the cons from the sequence, used to find the replacement of the gapped \"N\"s\n",
      "\n",
      "#todo: change the marix in this one\n",
      "import pysam\n",
      "\n",
      "def con_matrix(samfile,chro,start,end):\n",
      "    \"\"\"\n",
      "    the samfile should be opened outside the function to avoid too much I/O\n",
      "    from the same region of the bam file, get all the sequence from read for each position\n",
      "    return 5 list: ATGC DEL\n",
      "    \"\"\"\n",
      "    #initiate the matrix\n",
      "    gaplength=end-start # note the end need to be +1 in the input, from the N_list\n",
      "    A=[0]*gaplength\n",
      "    C=[0]*gaplength\n",
      "    G=[0]*gaplength\n",
      "    T=[0]*gaplength\n",
      "    DEL=[0]*gaplength\n",
      "    \n",
      "    #write values to the matrix\n",
      "    n=0\n",
      "    for pileupcolumn in samfile.pileup(chro,start,end, truncate=True):\n",
      "        for pileupread in pileupcolumn.pileups:\n",
      "            site_seq=pileupread.alignment.query_sequence[pileupread.query_position]\n",
      "            #test if it is del first\n",
      "            if pileupread.is_del:\n",
      "                DEL[n]+=1\n",
      "            elif site_seq in \"Aa\":\n",
      "                A[n]+=1\n",
      "            elif site_seq in \"Cc\":\n",
      "                C[n]+=1\n",
      "            elif site_seq in \"Gg\":\n",
      "                G[n]+=1\n",
      "            elif site_seq in \"Tt\":\n",
      "                T[n]+=1\n",
      "        \n",
      "        coverage=pileupcolumn.n  # for each site, get the coverage, the coverage should be expained fullly by the deletion and the nuclitides\n",
      "        #add a test of coverage\n",
      "        if coverage==(DEL[n]+A[n]+C[n]+G[n]+T[n]):\n",
      "            pass\n",
      "        else:\n",
      "            print \"Coverage count error at %s:%s\" % (chro,pileupcolumn.pos)\n",
      "        n+=1\n",
      "    \n",
      "    return (DEL,A,C,G,T)\n",
      "\n",
      "def cons(DEL,A,C,G,T):\n",
      "    \"\"\"\n",
      "    Given: four list contains the DEL,A,C,G,T frenqency\n",
      "    Return: the consensus string of the matrix\n",
      "    \"\"\"\n",
      "    cons_string=[]\n",
      "    for i in range(0,len(A)):\n",
      "        col={\"-\":DEL[i],\"A\":A[i], \"C\":C[i], \"G\":G[i], \"T\":T[i]}\n",
      "        max_n=max(col.values())\n",
      "        #avoid no coverage status\n",
      "        if max_n==0:\n",
      "            pass\n",
      "        else:\n",
      "        #design model: search\n",
      "            for key in col.keys():\n",
      "                if col[key]==max_n:\n",
      "                    cons_string.append(key)\n",
      "                    #just take the first as best\n",
      "                    break\n",
      "                    #count+=1\n",
      "                #if count>1:\n",
      "                    #print \"Dupilicated best!\"\n",
      "    return \"\".join(cons_string)\n",
      "\n",
      "if \"__name__\"==\"__main__\":\n",
      "    samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "    for N_single in N_list:\n",
      "        chro, start,end =N_single\n",
      "        if end-start>24:\n",
      "            print chr_select(record_dict, chro,start,end+1)\n",
      "            DEL,A,C,G,T=con_matrix(samfile, chro,start,end+1)\n",
      "            aa=cons(DEL,A,C,G,T)\n",
      "            \n",
      "    samfile.close()\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for pileupcolumn in samfile.pileup(chro,start,end+1, truncate=True):\n",
      "    print (\"\\ncoverage at base %s = %s\" %\n",
      "            (pileupcolumn.pos, pileupcolumn.n))\n",
      "    for pileupread in pileupcolumn.pileups:\n",
      "        print pileupread.alignment.query_sequence[pileupread.query_position]\n",
      "        print pileupread.is_del  #if this position is a deletion,then the replacemnet can be ignored\n",
      "        print pileupread.indel\n",
      "        \n",
      "        \n",
      "# the test code for main\n",
      "    print N_list[19]\n",
      "    chro, start,end =N_list[19]\n",
      "    print chr_select(record_dict, chro,start,end+1)\n",
      "    \n",
      "    samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "    DEL,A,C,G,T=con_matrix(samfile, chro,start,end+1)\n",
      "    aa=cons(DEL,A,C,G,T)\n",
      "    print aa\n",
      "    print len(aa)\n",
      "    print end+1-start\n",
      "    samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pysam\n",
      "\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\")\n",
      "\n",
      "for N_single in N_list:\n",
      "    chro, start,end=N_single\n",
      "    if end-start>24:\n",
      "        print \"T\"\n",
      "        for pileupcolumn in samfile.pileup(chro,start,end+1, truncate=True):\n",
      "            print (\"\\ncoverage at base %s = %s\" % (pileupcolumn.pos, pileupcolumn.n))\n",
      "samfile.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-6-88f4df480ae1>, line 11)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-88f4df480ae1>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    samfile.close()\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# filename: bam2coverage.py\n",
      "# from bam file get the coverage as\n",
      "# the following is the test code\n",
      "\n",
      "\n",
      "\n",
      "import pysam\n",
      "samfile = pysam.AlignmentFile(\"cb12i_s.bam\", \"rb\" )\n",
      "for pileupcolumn in samfile.pileup(\"II\",6029640,6029655):\n",
      "    if pileupcolumn.pos in range(6029640,6029655+1):\n",
      "        print (\"\\ncoverage at base %s = %s\" %\n",
      "                (pileupcolumn.pos, pileupcolumn.n))\n",
      "        for pileupread in pileupcolumn.pileups:\n",
      "            print pileupread.query_position,\n",
      "            print pileupread.indel\n",
      "            print ('\\tbase in read %s = %s' %\n",
      "                    (pileupread.alignment.query_name,\n",
      "                     pileupread.alignment.query_sequence[pileupread.query_position]))\n",
      "samfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pysama",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-39-f0f61380c002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# from bam file get the coverage as\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# the following is the test code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpysama\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msamfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cb12i_s.bam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpileupcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpileup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"II\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6029640\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6029655\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named pysama"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "muscle -in support_read.fasta -out aaaaa.html  -diags -maxiters 1 -html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bp_describe.txt                 cb_edge_s.bam\r\n",
        "cb12i_s.bam                     cb_edge_s.bam.bai\r\n",
        "cb12i_s.bam.bai                 edge.fasta\r\n",
        "cb4_bp.bam                      ipython.out\r\n",
        "\u001b[0m\u001b[01;32mcb4_bp.fasta\u001b[0m*                   networkx_test.ipynb\r\n",
        "cb4_bp.sam                      nfill-Copy0.ipynb\r\n",
        "cb4_bp_s.bam                    nfill.ipynb\r\n",
        "cb4_bp_s.bam.bai                N_list.dat\r\n",
        "cb4_bp_select.fasta             nohup.out\r\n",
        "cb4_insertion_filled.fasta      pysam_test.ipynb\r\n",
        "cb4_insertion_filled.fasta.amb  pysam_use-checkpoint.ipynb\r\n",
        "cb4_insertion_filled.fasta.ann  pysam_use-Copy0.ipynb\r\n",
        "cb4_insertion_filled.fasta.bwt  pysam_use-Copy1.ipynb\r\n",
        "cb4_insertion_filled.fasta.pac  pysam_use-Copy2.ipynb\r\n",
        "cb4_insertion_filled.fasta.sa   pysam_use.ipynb\r\n",
        "\u001b[01;32mcb_bp.txt\u001b[0m*                      \u001b[01;34mselect\u001b[0m/\r\n",
        "cb_edge.bam                     support_read.fasta\r\n",
        "cb_edge.sam                     V_random\r\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fill_N(record_dict, N_list):\n",
      "    for n_range in N_list:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}